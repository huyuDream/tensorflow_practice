#生成第一个模型，并用tf_serving进行加载
准备好两个容器, 详见 1_docker
本文使用container name为: tensorflow_219、tf_serving_dev

两容器目录共享，省去拷贝模型步骤。

# 生成模型 -- 线性回归模型
first_model.py 参照官方实例
https://tensorflow.google.cn/tutorials/quickstart/beginner?hl=zh-cn

在最后新增到导出模型
model.export("./model_output/20250910/")

执行成功后在./model_output/便可看到相应的模型


# 启动tf_serving命令
{your_path}/tensorflow_model_server --model_base_path={your_path} \
                                       --model_name={model_name} \
                                       --rest_api_port=8502

# 启动tf_serving命令
./bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \
    --model_base_path=/home/src/tensorflow_practice/2_first_model/model_output/ \
    --model_name=test \
    --rest_api_port=8502


# 查询模型接口
# http://127.0.0.1:8502/v1/models/{{model_name}}/metadata
curl http://127.0.0.1:8502/v1/models/test/metadata

可以看到函数签名信息

